import { flatten, compact, min, max, isEqual } from 'lodash';
import * as DMP from 'diff-match-patch';
import { uuid } from '@sanity/uuid';
import debugIt from 'debug';

// TODO: Support '*'
const digitChar = /[0-9]/;
const attributeCharMatcher = /^[a-zA-Z0-9_]$/;
const attributeFirstCharMatcher = /^[a-zA-Z_]$/;
const symbols = {
    operator: ['..', '.', ',', ':', '?'],
    comparator: ['>', '>=', '<', '<=', '==', '!='],
    keyword: ['$', '@'],
    boolean: ['true', 'false'],
    paren: ['[', ']'],
};
const symbolClasses = Object.keys(symbols);
/**
 * Tokenizes a jsonpath2 expression
 */
class Tokenizer {
    source;
    i;
    length;
    tokenizers;
    constructor(path) {
        this.source = path;
        this.length = path.length;
        this.i = 0;
        this.tokenizers = [
            this.tokenizeSymbol,
            this.tokenizeIdentifier,
            this.tokenizeNumber,
            this.tokenizeQuoted,
        ].map((fn) => fn.bind(this));
    }
    tokenize() {
        const result = [];
        while (!this.EOF()) {
            this.chompWhitespace();
            let token = null;
            // @todo refactor into a simpler `.find()`?
            const found = this.tokenizers.some((tokenizer) => {
                token = tokenizer();
                return Boolean(token);
            });
            if (!found || !token) {
                throw new Error(`Invalid tokens in jsonpath '${this.source}' @ ${this.i}`);
            }
            result.push(token);
        }
        return result;
    }
    takeWhile(fn) {
        const start = this.i;
        let result = '';
        while (!this.EOF()) {
            const nextChar = fn(this.source[this.i]);
            if (nextChar === null) {
                break;
            }
            result += nextChar;
            this.i++;
        }
        if (this.i === start) {
            return null;
        }
        return result;
    }
    EOF() {
        return this.i >= this.length;
    }
    peek() {
        if (this.EOF()) {
            return null;
        }
        return this.source[this.i];
    }
    consume(str) {
        if (this.i + str.length > this.length) {
            throw new Error(`Expected ${str} at end of jsonpath`);
        }
        if (str === this.source.slice(this.i, this.i + str.length)) {
            this.i += str.length;
        }
        else {
            throw new Error(`Expected "${str}", but source contained "${this.source.slice()}`);
        }
    }
    // Tries to match the upcoming bit of string with the provided string. If it matches, returns
    // the string, then advances the read pointer to the next bit. If not, returns null and nothing
    // happens.
    tryConsume(str) {
        if (this.i + str.length > this.length) {
            return null;
        }
        if (str === this.source.slice(this.i, this.i + str.length)) {
            this.i += str.length;
            return str;
        }
        return null;
    }
    chompWhitespace() {
        this.takeWhile((char) => {
            return char === ' ' ? '' : null;
        });
    }
    tokenizeQuoted() {
        const quote = this.peek();
        if (quote === "'" || quote === '"') {
            this.consume(quote);
            let escape = false;
            const inner = this.takeWhile((char) => {
                if (escape) {
                    escape = false;
                    return char;
                }
                if (char === '\\') {
                    escape = true;
                    return '';
                }
                if (char != quote) {
                    return char;
                }
                return null;
            });
            this.consume(quote);
            return {
                type: 'quoted',
                value: inner,
                quote: quote === '"' ? 'double' : 'single',
            };
        }
        return null;
    }
    tokenizeIdentifier() {
        let first = true;
        const identifier = this.takeWhile((char) => {
            if (first) {
                first = false;
                return char.match(attributeFirstCharMatcher) ? char : null;
            }
            return char.match(attributeCharMatcher) ? char : null;
        });
        if (identifier !== null) {
            return {
                type: 'identifier',
                name: identifier,
            };
        }
        return null;
    }
    tokenizeNumber() {
        const start = this.i;
        let dotSeen = false;
        let digitSeen = false;
        let negative = false;
        if (this.peek() === '-') {
            negative = true;
            this.consume('-');
        }
        const number = this.takeWhile((char) => {
            if (char === '.' && !dotSeen && digitSeen) {
                dotSeen = true;
                return char;
            }
            digitSeen = true;
            return char.match(digitChar) ? char : null;
        });
        if (number !== null) {
            return {
                type: 'number',
                value: negative ? -number : +number,
                raw: negative ? `-${number}` : number,
            };
        }
        // No number, rewind
        this.i = start;
        return null;
    }
    tokenizeSymbol() {
        for (const symbolClass of symbolClasses) {
            const patterns = symbols[symbolClass];
            const symbol = patterns.find((pattern) => this.tryConsume(pattern));
            if (symbol) {
                return {
                    type: symbolClass,
                    symbol,
                };
            }
        }
        return null;
    }
}
function tokenize(jsonpath) {
    return new Tokenizer(jsonpath).tokenize();
}

// Converts a string into an abstract syntax tree representation
// TODO: Support '*'
class Parser {
    tokens;
    length;
    i;
    constructor(path) {
        this.tokens = tokenize(path);
        this.length = this.tokens.length;
        this.i = 0;
    }
    parse() {
        return this.parsePath();
    }
    EOF() {
        return this.i >= this.length;
    }
    // Look at upcoming token
    peek() {
        if (this.EOF()) {
            return null;
        }
        return this.tokens[this.i];
    }
    consume() {
        const result = this.peek();
        this.i += 1;
        return result;
    }
    // Return next token if it matches the pattern
    probe(pattern) {
        const token = this.peek();
        if (!token) {
            return null;
        }
        const record = token;
        const match = Object.keys(pattern).every((key) => {
            return key in token && pattern[key] === record[key];
        });
        return match ? token : null;
    }
    // Return and consume next token if it matches the pattern
    match(pattern) {
        return this.probe(pattern) ? this.consume() : null;
    }
    parseAttribute() {
        const token = this.match({ type: 'identifier' });
        if (token && token.type === 'identifier') {
            return {
                type: 'attribute',
                name: token.name,
            };
        }
        const quoted = this.match({ type: 'quoted', quote: 'single' });
        if (quoted && quoted.type === 'quoted') {
            return {
                type: 'attribute',
                name: quoted.value || '',
            };
        }
        return null;
    }
    parseAlias() {
        if (this.match({ type: 'keyword', symbol: '@' }) || this.match({ type: 'keyword', symbol: '$' })) {
            return {
                type: 'alias',
                target: 'self',
            };
        }
        return null;
    }
    parseNumber() {
        const token = this.match({ type: 'number' });
        if (token && token.type === 'number') {
            return {
                type: 'number',
                value: token.value,
            };
        }
        return null;
    }
    parseNumberValue() {
        const expr = this.parseNumber();
        if (expr) {
            return expr.value;
        }
        return null;
    }
    parseSliceSelector() {
        const start = this.i;
        const rangeStart = this.parseNumberValue();
        const colon1 = this.match({ type: 'operator', symbol: ':' });
        if (!colon1) {
            if (rangeStart === null) {
                // Rewind, this was actually nothing
                this.i = start;
                return null;
            }
            // Unwrap, this was just a single index not followed by colon
            return { type: 'index', value: rangeStart };
        }
        const result = {
            type: 'range',
            start: rangeStart,
            end: this.parseNumberValue(),
        };
        const colon2 = this.match({ type: 'operator', symbol: ':' });
        if (colon2) {
            result.step = this.parseNumberValue();
        }
        if (result.start === null && result.end === null) {
            // rewind, this wasnt' a slice selector
            this.i = start;
            return null;
        }
        return result;
    }
    parseValueReference() {
        return this.parseAttribute() || this.parseSliceSelector();
    }
    parseLiteralValue() {
        const literalString = this.match({ type: 'quoted', quote: 'double' });
        if (literalString && literalString.type === 'quoted') {
            return {
                type: 'string',
                value: literalString.value || '',
            };
        }
        const literalBoolean = this.match({ type: 'boolean' });
        if (literalBoolean && literalBoolean.type === 'boolean') {
            return {
                type: 'boolean',
                value: literalBoolean.symbol === 'true',
            };
        }
        return this.parseNumber();
    }
    // TODO: Reorder constraints so that literal value is always on rhs, and variable is always
    // on lhs.
    parseFilterExpression() {
        const start = this.i;
        const expr = this.parseAttribute() || this.parseAlias();
        if (!expr) {
            return null;
        }
        if (this.match({ type: 'operator', symbol: '?' })) {
            return {
                type: 'constraint',
                operator: '?',
                lhs: expr,
            };
        }
        const binOp = this.match({ type: 'comparator' });
        if (!binOp || binOp.type !== 'comparator') {
            // No expression, rewind!
            this.i = start;
            return null;
        }
        const lhs = expr;
        const rhs = this.parseLiteralValue();
        if (!rhs) {
            throw new Error(`Operator ${binOp.symbol} needs a literal value at the right hand side`);
        }
        return {
            type: 'constraint',
            operator: binOp.symbol,
            lhs: lhs,
            rhs: rhs,
        };
    }
    parseExpression() {
        return this.parseFilterExpression() || this.parseValueReference();
    }
    parseUnion() {
        if (!this.match({ type: 'paren', symbol: '[' })) {
            return null;
        }
        const terms = [];
        let expr = this.parseFilterExpression() || this.parsePath() || this.parseValueReference();
        while (expr) {
            terms.push(expr);
            // End of union?
            if (this.match({ type: 'paren', symbol: ']' })) {
                break;
            }
            if (!this.match({ type: 'operator', symbol: ',' })) {
                throw new Error('Expected ]');
            }
            expr = this.parseFilterExpression() || this.parsePath() || this.parseValueReference();
            if (!expr) {
                throw new Error("Expected expression following ','");
            }
        }
        return {
            type: 'union',
            nodes: terms,
        };
    }
    parseRecursive() {
        if (!this.match({ type: 'operator', symbol: '..' })) {
            return null;
        }
        const subpath = this.parsePath();
        if (!subpath) {
            throw new Error("Expected path following '..' operator");
        }
        return {
            type: 'recursive',
            term: subpath,
        };
    }
    parsePath() {
        const nodes = [];
        const expr = this.parseAttribute() || this.parseUnion() || this.parseRecursive();
        if (!expr) {
            return null;
        }
        nodes.push(expr);
        while (!this.EOF()) {
            if (this.match({ type: 'operator', symbol: '.' })) {
                const attr = this.parseAttribute();
                if (!attr) {
                    throw new Error("Expected attribute name following '.");
                }
                nodes.push(attr);
                continue;
            }
            else if (this.probe({ type: 'paren', symbol: '[' })) {
                const union = this.parseUnion();
                if (!union) {
                    throw new Error("Expected union following '['");
                }
                nodes.push(union);
            }
            else {
                const recursive = this.parseRecursive();
                if (recursive) {
                    nodes.push(recursive);
                }
                break;
            }
        }
        if (nodes.length === 1) {
            return nodes[0];
        }
        return {
            type: 'path',
            nodes: nodes,
        };
    }
}
function parseJsonPath(path) {
    const parsed = new Parser(path).parse();
    if (!parsed) {
        throw new Error(`Failed to parse JSON path "${path}"`);
    }
    return parsed;
}

/**
 * Splits an expression into a set of heads, tails. A head is the next leaf node to
 * check for matches, and a tail is everything that follows it. Matching is done by
 * matching heads, then proceedint to the matching value, splitting the tail into
 * heads and tails and checking the heads against the new value, and so on.
 */
function descend$1(tail) {
    const [head, newTail] = splitIfPath(tail);
    if (!head) {
        throw new Error('Head cannot be null');
    }
    return spreadIfUnionHead(head, newTail);
}
// Split path in [head, tail]
function splitIfPath(tail) {
    if (tail.type !== 'path') {
        return [tail, null];
    }
    const nodes = tail.nodes;
    if (nodes.length === 0) {
        return [null, null];
    }
    if (nodes.length === 1) {
        return [nodes[0], null];
    }
    return [nodes[0], { type: 'path', nodes: nodes.slice(1) }];
}
function concatPaths(path1, path2) {
    if (!path1 && !path2) {
        return null;
    }
    const nodes1 = path1 ? path1.nodes : [];
    const nodes2 = path2 ? path2.nodes : [];
    return {
        type: 'path',
        nodes: nodes1.concat(nodes2),
    };
}
// Spreads a union head into several heads/tails
function spreadIfUnionHead(head, tail) {
    if (head.type !== 'union') {
        return [[head, tail]];
    }
    return head.nodes.map((node) => {
        if (node.type === 'path') {
            const [subHead, subTail] = splitIfPath(node);
            return [subHead, concatPaths(subTail, tail)];
        }
        return [node, tail];
    });
}

/**
 * Converts a parsed expression back into jsonpath2, roughly -
 * mostly for use with tests.
 *
 * @param expr - Expression to convert to path
 * @returns a string representation of the path
 * @internal
 */
function toPath(expr) {
    return toPathInner(expr, false);
}
function toPathInner(expr, inUnion) {
    switch (expr.type) {
        case 'attribute':
            return expr.name;
        case 'alias':
            return expr.target === 'self' ? '@' : '$';
        case 'number':
            return `${expr.value}`;
        case 'range': {
            const result = [];
            if (!inUnion) {
                result.push('[');
            }
            if (expr.start) {
                result.push(`${expr.start}`);
            }
            result.push(':');
            if (expr.end) {
                result.push(`${expr.end}`);
            }
            if (expr.step) {
                result.push(`:${expr.step}`);
            }
            if (!inUnion) {
                result.push(']');
            }
            return result.join('');
        }
        case 'index':
            if (inUnion) {
                return `${expr.value}`;
            }
            return `[${expr.value}]`;
        case 'constraint': {
            const rhs = expr.rhs ? ` ${toPathInner(expr.rhs, false)}` : '';
            const inner = `${toPathInner(expr.lhs, false)} ${expr.operator}${rhs}`;
            if (inUnion) {
                return inner;
            }
            return `[${inner}]`;
        }
        case 'string':
            return JSON.stringify(expr.value);
        case 'path': {
            const result = [];
            const nodes = expr.nodes.slice();
            while (nodes.length > 0) {
                const node = nodes.shift();
                if (node) {
                    result.push(toPath(node));
                }
                const upcoming = nodes[0];
                if (upcoming && toPathInner(upcoming, false)[0] !== '[') {
                    result.push('.');
                }
            }
            return result.join('');
        }
        case 'union':
            return `[${expr.nodes.map((e) => toPathInner(e, true)).join(',')}]`;
        default:
            throw new Error(`Unknown node type ${expr.type}`);
        case 'recursive':
            return `..${toPathInner(expr.term, false)}`;
    }
}

// A utility wrapper class to process parsed jsonpath expressions
class Expression {
    expr;
    constructor(expr) {
        if (!expr) {
            throw new Error('Attempted to create Expression from null-value');
        }
        // This is a wrapped expr
        if ('expr' in expr) {
            this.expr = expr.expr;
        }
        else {
            this.expr = expr;
        }
        if (!('type' in this.expr)) {
            throw new Error('Attempt to create Expression for expression with no type');
        }
    }
    isPath() {
        return this.expr.type === 'path';
    }
    isUnion() {
        return this.expr.type === 'union';
    }
    isCollection() {
        return this.isPath() || this.isUnion();
    }
    isConstraint() {
        return this.expr.type === 'constraint';
    }
    isRecursive() {
        return this.expr.type === 'recursive';
    }
    isExistenceConstraint() {
        return this.expr.type === 'constraint' && this.expr.operator === '?';
    }
    isIndex() {
        return this.expr.type === 'index';
    }
    isRange() {
        return this.expr.type === 'range';
    }
    expandRange(probe) {
        const probeLength = () => {
            if (!probe) {
                throw new Error('expandRange() required a probe that was not passed');
            }
            return probe.length();
        };
        let start = 'start' in this.expr ? this.expr.start || 0 : 0;
        start = interpretNegativeIndex(start, probe);
        let end = 'end' in this.expr ? this.expr.end || probeLength() : probeLength();
        end = interpretNegativeIndex(end, probe);
        const step = 'step' in this.expr ? this.expr.step || 1 : 1;
        return { start, end, step };
    }
    isAttributeReference() {
        return this.expr.type === 'attribute';
    }
    // Is a range or index -> something referencing indexes
    isIndexReference() {
        return this.isIndex() || this.isRange();
    }
    name() {
        return 'name' in this.expr ? this.expr.name : '';
    }
    isSelfReference() {
        return this.expr.type === 'alias' && this.expr.target === 'self';
    }
    constraintTargetIsSelf() {
        return (this.expr.type === 'constraint' &&
            this.expr.lhs.type === 'alias' &&
            this.expr.lhs.target === 'self');
    }
    constraintTargetIsAttribute() {
        return this.expr.type === 'constraint' && this.expr.lhs.type === 'attribute';
    }
    testConstraint(probe) {
        const expr = this.expr;
        if (expr.type === 'constraint' && expr.lhs.type === 'alias' && expr.lhs.target === 'self') {
            if (probe.containerType() !== 'primitive') {
                return false;
            }
            if (expr.type === 'constraint' && expr.operator === '?') {
                return true;
            }
            const lhs = probe.get();
            const rhs = expr.rhs && 'value' in expr.rhs ? expr.rhs.value : undefined;
            return testBinaryOperator(lhs, expr.operator, rhs);
        }
        if (expr.type !== 'constraint') {
            return false;
        }
        const lhs = expr.lhs;
        if (!lhs) {
            throw new Error('No LHS of expression');
        }
        if (lhs.type !== 'attribute') {
            throw new Error(`Constraint target ${lhs.type} not supported`);
        }
        if (probe.containerType() !== 'object') {
            return false;
        }
        const lhsValue = probe.getAttribute(lhs.name);
        if (lhsValue === undefined || lhsValue === null || lhsValue.containerType() !== 'primitive') {
            // LHS is void and empty, or it is a collection
            return false;
        }
        if (this.isExistenceConstraint()) {
            // There is no rhs, and if we're here the key did exist
            return true;
        }
        const rhs = expr.rhs && 'value' in expr.rhs ? expr.rhs.value : undefined;
        return testBinaryOperator(lhsValue.get(), expr.operator, rhs);
    }
    pathNodes() {
        return this.expr.type === 'path' ? this.expr.nodes : [this.expr];
    }
    prepend(node) {
        if (!node) {
            return this;
        }
        return new Expression({
            type: 'path',
            nodes: node.pathNodes().concat(this.pathNodes()),
        });
    }
    concat(other) {
        return other ? other.prepend(this) : this;
    }
    descend() {
        return descend$1(this.expr).map((headTail) => {
            const [head, tail] = headTail;
            return {
                head: head ? new Expression(head) : null,
                tail: tail ? new Expression(tail) : null,
            };
        });
    }
    unwrapRecursive() {
        if (this.expr.type !== 'recursive') {
            throw new Error(`Attempt to unwrap recursive on type ${this.expr.type}`);
        }
        return new Expression(this.expr.term);
    }
    toIndicies(probe) {
        if (this.expr.type !== 'index' && this.expr.type !== 'range') {
            throw new Error('Node cannot be converted to indexes');
        }
        if (this.expr.type === 'index') {
            return [interpretNegativeIndex(this.expr.value, probe)];
        }
        const result = [];
        const range = this.expandRange(probe);
        let { start, end } = range;
        if (range.step < 0) {
            [start, end] = [end, start];
        }
        for (let i = start; i < end; i++) {
            result.push(i);
        }
        return result;
    }
    toFieldReferences() {
        if (this.isIndexReference()) {
            return this.toIndicies();
        }
        if (this.expr.type === 'attribute') {
            return [this.expr.name];
        }
        throw new Error(`Can't convert ${this.expr.type} to field references`);
    }
    toString() {
        return toPath(this.expr);
    }
    static fromPath(path) {
        const parsed = parseJsonPath(path);
        if (!parsed) {
            throw new Error(`Failed to parse path "${path}"`);
        }
        return new Expression(parsed);
    }
    static attributeReference(name) {
        return new Expression({
            type: 'attribute',
            name: name,
        });
    }
    static indexReference(i) {
        return new Expression({
            type: 'index',
            value: i,
        });
    }
}
// Tests an operator on two given primitive values
function testBinaryOperator(lhsValue, operator, rhsValue) {
    switch (operator) {
        case '>':
            return lhsValue > rhsValue;
        case '>=':
            return lhsValue >= rhsValue;
        case '<':
            return lhsValue < rhsValue;
        case '<=':
            return lhsValue <= rhsValue;
        case '==':
            return lhsValue === rhsValue;
        case '!=':
            return lhsValue !== rhsValue;
        default:
            throw new Error(`Unsupported binary operator ${operator}`);
    }
}
function interpretNegativeIndex(index, probe) {
    if (index >= 0) {
        return index;
    }
    if (!probe) {
        throw new Error('interpretNegativeIndex() must have a probe when < 0');
    }
    return index + probe.length();
}

/**
 * Descender models the state of one partial jsonpath evaluation. Head is the
 * next thing to match, tail is the upcoming things once the head is matched.
 */
class Descender {
    head;
    tail;
    constructor(head, tail) {
        this.head = head;
        this.tail = tail;
    }
    // Iterate this descender once processing any constraints that are
    // resolvable on the current value. Returns an array of new descenders
    // that are guaranteed to be without constraints in the head
    iterate(probe) {
        let result = [this];
        if (this.head && this.head.isConstraint()) {
            let anyConstraints = true;
            // Keep rewriting constraints until there are none left
            while (anyConstraints) {
                result = flatten(result.map((descender) => {
                    return descender.iterateConstraints(probe);
                }));
                anyConstraints = result.some((descender) => {
                    return descender.head && descender.head.isConstraint();
                });
            }
        }
        return result;
    }
    isRecursive() {
        return Boolean(this.head && this.head.isRecursive());
    }
    hasArrived() {
        return this.head === null && this.tail === null;
    }
    extractRecursives() {
        if (this.head && this.head.isRecursive()) {
            const term = this.head.unwrapRecursive();
            return new Descender(null, term.concat(this.tail)).descend();
        }
        return [];
    }
    iterateConstraints(probe) {
        const head = this.head;
        if (head === null || !head.isConstraint()) {
            // Not a constraint, no rewrite
            return [this];
        }
        const result = [];
        if (probe.containerType() === 'primitive' && head.constraintTargetIsSelf()) {
            if (head.testConstraint(probe)) {
                result.push(...this.descend());
            }
            return result;
        }
        // The value is an array
        if (probe.containerType() === 'array') {
            const length = probe.length();
            for (let i = 0; i < length; i++) {
                // Push new descenders with constraint translated to literal indices
                // where they match
                const constraint = probe.getIndex(i);
                if (constraint && head.testConstraint(constraint)) {
                    result.push(new Descender(new Expression({ type: 'index', value: i }), this.tail));
                }
            }
            return result;
        }
        // The value is an object
        if (probe.containerType() === 'object') {
            if (head.constraintTargetIsSelf()) {
                // There are no matches for target self ('@') on a plain object
                return [];
            }
            if (head.testConstraint(probe)) {
                return this.descend();
            }
            return result;
        }
        return result;
    }
    descend() {
        if (!this.tail) {
            return [new Descender(null, null)];
        }
        return this.tail.descend().map((ht) => {
            return new Descender(ht.head, ht.tail);
        });
    }
    toString() {
        const result = ['<'];
        if (this.head) {
            result.push(this.head.toString());
        }
        result.push('|');
        if (this.tail) {
            result.push(this.tail.toString());
        }
        result.push('>');
        return result.join('');
    }
}

/**
 * @internal
 */
class Matcher {
    active;
    recursives;
    payload;
    constructor(active, parent) {
        this.active = active || [];
        if (parent) {
            this.recursives = parent.recursives;
            this.payload = parent.payload;
        }
        else {
            this.recursives = [];
        }
        this.extractRecursives();
    }
    setPayload(payload) {
        this.payload = payload;
        return this;
    }
    // Moves any recursive descenders onto the recursive track, removing them from
    // the active set
    extractRecursives() {
        this.active = this.active.filter((descender) => {
            if (descender.isRecursive()) {
                this.recursives.push(...descender.extractRecursives());
                return false;
            }
            return true;
        });
    }
    // Find recursives that are relevant now and should be considered part of the active set
    activeRecursives(probe) {
        return this.recursives.filter((descender) => {
            const head = descender.head;
            if (!head) {
                return false;
            }
            // Constraints are always relevant
            if (head.isConstraint()) {
                return true;
            }
            // Index references are only relevant for indexable values
            if (probe.containerType() === 'array' && head.isIndexReference()) {
                return true;
            }
            // Attribute references are relevant for plain objects
            if (probe.containerType() === 'object') {
                return head.isAttributeReference() && probe.hasAttribute(head.name());
            }
            return false;
        });
    }
    match(probe) {
        return this.iterate(probe).extractMatches(probe);
    }
    iterate(probe) {
        const newActiveSet = [];
        this.active.concat(this.activeRecursives(probe)).forEach((descender) => {
            newActiveSet.push(...descender.iterate(probe));
        });
        return new Matcher(newActiveSet, this);
    }
    // Returns true if any of the descenders in the active or recursive set
    // consider the current state a final destination
    isDestination() {
        return this.active.some((descender) => descender.hasArrived());
    }
    hasRecursives() {
        return this.recursives.length > 0;
    }
    // Returns any payload delivieries and leads that needs to be followed to complete
    // the process.
    extractMatches(probe) {
        const leads = [];
        const targets = [];
        this.active.forEach((descender) => {
            if (descender.hasArrived()) {
                // This was already arrived, so matches this value, not descenders
                targets.push(new Expression({
                    type: 'alias',
                    target: 'self',
                }));
                return;
            }
            const descenderHead = descender.head;
            if (!descenderHead) {
                return;
            }
            if (probe.containerType() === 'array' && !descenderHead.isIndexReference()) {
                // This descender does not match an indexable value
                return;
            }
            if (probe.containerType() === 'object' && !descenderHead.isAttributeReference()) {
                // This descender never match a plain object
                return;
            }
            if (descender.tail) {
                // Not arrived yet
                const matcher = new Matcher(descender.descend(), this);
                descenderHead.toFieldReferences().forEach(() => {
                    leads.push({
                        target: descenderHead,
                        matcher: matcher,
                    });
                });
            }
            else {
                // arrived
                targets.push(descenderHead);
            }
        });
        // If there are recursive terms, we need to add a lead for every descendant ...
        if (this.hasRecursives()) {
            // The recustives matcher will have no active set, only inherit recursives from this
            const recursivesMatcher = new Matcher([], this);
            if (probe.containerType() === 'array') {
                const length = probe.length();
                for (let i = 0; i < length; i++) {
                    leads.push({
                        target: Expression.indexReference(i),
                        matcher: recursivesMatcher,
                    });
                }
            }
            else if (probe.containerType() === 'object') {
                probe.attributeKeys().forEach((name) => {
                    leads.push({
                        target: Expression.attributeReference(name),
                        matcher: recursivesMatcher,
                    });
                });
            }
        }
        return targets.length > 0
            ? { leads: leads, delivery: { targets, payload: this.payload } }
            : { leads: leads };
    }
    static fromPath(jsonpath) {
        const path = parseJsonPath(jsonpath);
        if (!path) {
            throw new Error(`Failed to parse path from "${jsonpath}"`);
        }
        const descender = new Descender(null, new Expression(path));
        return new Matcher(descender.descend());
    }
}

function isRecord$1(value) {
    return value !== null && typeof value === 'object';
}

// A default implementation of a probe for vanilla JS _values
class PlainProbe {
    _value;
    path;
    constructor(value, path) {
        this._value = value;
        this.path = path || [];
    }
    containerType() {
        if (Array.isArray(this._value)) {
            return 'array';
        }
        else if (this._value !== null && typeof this._value === 'object') {
            return 'object';
        }
        return 'primitive';
    }
    length() {
        if (!Array.isArray(this._value)) {
            throw new Error("Won't return length of non-indexable _value");
        }
        return this._value.length;
    }
    getIndex(i) {
        if (!Array.isArray(this._value)) {
            return false;
        }
        if (i >= this.length()) {
            return null;
        }
        return new PlainProbe(this._value[i], this.path.concat(i));
    }
    hasAttribute(key) {
        if (!isRecord$1(this._value)) {
            return false;
        }
        return this._value.hasOwnProperty(key);
    }
    attributeKeys() {
        return isRecord$1(this._value) ? Object.keys(this._value) : [];
    }
    getAttribute(key) {
        if (!isRecord$1(this._value)) {
            throw new Error('getAttribute only applies to plain objects');
        }
        if (!this.hasAttribute(key)) {
            return null;
        }
        return new PlainProbe(this._value[key], this.path.concat(key));
    }
    get() {
        return this._value;
    }
}

function extractAccessors(path, value) {
    const result = [];
    const matcher = Matcher.fromPath(path).setPayload(function appendResult(values) {
        result.push(...values);
    });
    const accessor = new PlainProbe(value);
    descend(matcher, accessor);
    return result;
}
function descend(matcher, accessor) {
    const { leads, delivery } = matcher.match(accessor);
    leads.forEach((lead) => {
        accessorsFromTarget(lead.target, accessor).forEach((childAccessor) => {
            descend(lead.matcher, childAccessor);
        });
    });
    if (delivery) {
        delivery.targets.forEach((target) => {
            if (typeof delivery.payload === 'function') {
                delivery.payload(accessorsFromTarget(target, accessor));
            }
        });
    }
}
function accessorsFromTarget(target, accessor) {
    const result = [];
    if (target.isIndexReference()) {
        target.toIndicies(accessor).forEach((i) => {
            result.push(accessor.getIndex(i));
        });
    }
    else if (target.isAttributeReference()) {
        result.push(accessor.getAttribute(target.name()));
    }
    else if (target.isSelfReference()) {
        result.push(accessor);
    }
    else {
        throw new Error(`Unable to derive accessor for target ${target.toString()}`);
    }
    return compact(result);
}

/**
 * Extracts a value for the given JsonPath, and includes the specific path of where it was found
 *
 * @param path - Path to extract
 * @param value - Value to extract from
 * @returns An array of objects with `path` and `value` keys
 * @internal
 */
function extractWithPath(path, value) {
    const accessors = extractAccessors(path, value);
    return accessors.map((acc) => ({ path: acc.path, value: acc.get() }));
}

const IS_DOTTABLE = /^[a-z_$]+/;
/**
 * Converts a path in array form to a JSONPath string
 *
 * @param pathArray - Array of path segments
 * @returns String representation of the path
 * @internal
 */
function arrayToJSONMatchPath(pathArray) {
    let path = '';
    pathArray.forEach((segment, index) => {
        path += stringifySegment(segment, index === 0);
    });
    return path;
}
// Converts an array of simple values (strings, numbers only) to a jsonmatch path string.
function stringifySegment(segment, hasLeading) {
    if (typeof segment === 'number') {
        return `[${segment}]`;
    }
    if (isRecord$1(segment)) {
        const seg = segment;
        return Object.keys(segment)
            .map((key) => (isPrimitiveValue(seg[key]) ? `[${key}=="${seg[key]}"]` : ''))
            .join('');
    }
    if (typeof segment === 'string' && IS_DOTTABLE.test(segment)) {
        return hasLeading ? segment : `.${segment}`;
    }
    return `['${segment}']`;
}
function isPrimitiveValue(val) {
    switch (typeof val) {
        case 'number':
        case 'string':
        case 'boolean':
            return true;
        default:
            return false;
    }
}

class SetPatch {
    id;
    path;
    value;
    constructor(id, path, value) {
        this.id = id;
        this.path = path;
        this.value = value;
    }
    apply(targets, accessor) {
        let result = accessor;
        targets.forEach((target) => {
            if (target.isSelfReference()) {
                result = result.set(this.value);
            }
            else if (target.isIndexReference()) {
                target.toIndicies(accessor).forEach((i) => {
                    result = result.setIndex(i, this.value);
                });
            }
            else if (target.isAttributeReference()) {
                result = result.setAttribute(target.name(), this.value);
            }
            else {
                throw new Error(`Unable to apply to target ${target.toString()}`);
            }
        });
        return result;
    }
}

function performIncrement(previousValue, delta) {
    if (typeof previousValue !== 'number' || !Number.isFinite(previousValue)) {
        return previousValue;
    }
    return previousValue + delta;
}
class IncPatch {
    path;
    value;
    id;
    constructor(id, path, value) {
        this.path = path;
        this.value = value;
        this.id = id;
    }
    apply(targets, accessor) {
        let result = accessor;
        // The target must be a container type
        if (result.containerType() === 'primitive') {
            return result;
        }
        for (const target of targets) {
            if (target.isIndexReference()) {
                for (const index of target.toIndicies(accessor)) {
                    // Skip patching unless the index actually currently exists
                    const item = result.getIndex(index);
                    if (!item) {
                        continue;
                    }
                    const previousValue = item.get();
                    result = result.setIndex(index, performIncrement(previousValue, this.value));
                }
                continue;
            }
            if (target.isAttributeReference()) {
                const attribute = result.getAttribute(target.name());
                if (!attribute) {
                    continue;
                }
                const previousValue = attribute.get();
                result = result.setAttribute(target.name(), performIncrement(previousValue, this.value));
                continue;
            }
            throw new Error(`Unable to apply to target ${target.toString()}`);
        }
        return result;
    }
}

function targetsToIndicies(targets, accessor) {
    const result = [];
    targets.forEach((target) => {
        if (target.isIndexReference()) {
            result.push(...target.toIndicies(accessor));
        }
    });
    return result.sort();
}

class InsertPatch {
    location;
    path;
    items;
    id;
    constructor(id, location, path, items) {
        this.id = id;
        this.location = location;
        this.path = path;
        this.items = items;
    }
    apply(targets, accessor) {
        let result = accessor;
        if (accessor.containerType() !== 'array') {
            throw new Error('Attempt to apply insert patch to non-array value');
        }
        switch (this.location) {
            case 'before': {
                const pos = minIndex(targets, accessor);
                result = result.insertItemsAt(pos, this.items);
                break;
            }
            case 'after': {
                const pos = maxIndex(targets, accessor);
                result = result.insertItemsAt(pos + 1, this.items);
                break;
            }
            case 'replace': {
                // TODO: Properly implement ranges in compliance with content lake
                // This will only properly support single contiguous ranges
                const indicies = targetsToIndicies(targets, accessor);
                result = result.unsetIndices(indicies);
                result = result.insertItemsAt(indicies[0], this.items);
                break;
            }
            default: {
                throw new Error(`Unsupported location atm: ${this.location}`);
            }
        }
        return result;
    }
}
function minIndex(targets, accessor) {
    let result = min(targetsToIndicies(targets, accessor)) || 0;
    // Ranges may be zero-length and not turn up in indices
    targets.forEach((target) => {
        if (target.isRange()) {
            const { start } = target.expandRange();
            if (start < result) {
                result = start;
            }
        }
    });
    return result;
}
function maxIndex(targets, accessor) {
    let result = max(targetsToIndicies(targets, accessor)) || 0;
    // Ranges may be zero-length and not turn up in indices
    targets.forEach((target) => {
        if (target.isRange()) {
            const { end } = target.expandRange();
            if (end > result) {
                result = end;
            }
        }
    });
    return result;
}

class SetIfMissingPatch {
    id;
    path;
    value;
    constructor(id, path, value) {
        this.id = id;
        this.path = path;
        this.value = value;
    }
    apply(targets, accessor) {
        let result = accessor;
        targets.forEach((target) => {
            if (target.isIndexReference()) ;
            else if (target.isAttributeReference()) {
                if (!result.hasAttribute(target.name())) {
                    result = accessor.setAttribute(target.name(), this.value);
                }
            }
            else {
                throw new Error(`Unable to apply to target ${target.toString()}`);
            }
        });
        return result;
    }
}

class UnsetPatch {
    id;
    path;
    value;
    constructor(id, path) {
        this.id = id;
        this.path = path;
    }
    // eslint-disable-next-line class-methods-use-this
    apply(targets, accessor) {
        let result = accessor;
        switch (accessor.containerType()) {
            case 'array':
                result = result.unsetIndices(targetsToIndicies(targets, accessor));
                break;
            case 'object':
                targets.forEach((target) => {
                    result = result.unsetAttribute(target.name());
                });
                break;
            default:
                throw new Error('Target value is neither indexable or an object. This error should potentially just be silently ignored?');
        }
        return result;
    }
}

/* eslint-disable new-cap, camelcase */
const dmp = new DMP.diff_match_patch();
function applyPatch(patch, oldValue) {
    // Silently avoid patching if the value type is not string
    if (typeof oldValue !== 'string')
        return oldValue;
    return dmp.patch_apply(patch, oldValue)[0];
}
class DiffMatchPatch {
    path;
    dmpPatch;
    id;
    constructor(id, path, dmpPatchSrc) {
        this.id = id;
        this.path = path;
        this.dmpPatch = dmp.patch_fromText(dmpPatchSrc);
    }
    apply(targets, accessor) {
        let result = accessor;
        // The target must be a container type
        if (result.containerType() === 'primitive') {
            return result;
        }
        for (const target of targets) {
            if (target.isIndexReference()) {
                for (const index of target.toIndicies(accessor)) {
                    // Skip patching unless the index actually currently exists
                    const item = result.getIndex(index);
                    if (!item) {
                        continue;
                    }
                    const oldValue = item.get();
                    const nextValue = applyPatch(this.dmpPatch, oldValue);
                    result = result.setIndex(index, nextValue);
                }
                continue;
            }
            if (target.isAttributeReference() && result.hasAttribute(target.name())) {
                const attribute = result.getAttribute(target.name());
                if (!attribute) {
                    continue;
                }
                const oldValue = attribute.get();
                const nextValue = applyPatch(this.dmpPatch, oldValue);
                result = result.setAttribute(target.name(), nextValue);
                continue;
            }
            throw new Error(`Unable to apply diffMatchPatch to target ${target.toString()}`);
        }
        return result;
    }
}

// Parses a content lake patch into our own personal patch implementations
function parsePatch(patch) {
    const result = [];
    if (Array.isArray(patch)) {
        return patch.reduce((r, p) => r.concat(parsePatch(p)), result);
    }
    const { set, setIfMissing, unset, diffMatchPatch, inc, dec, insert } = patch;
    if (set) {
        Object.keys(set).forEach((path) => {
            result.push(new SetPatch(patch.id, path, set[path]));
        });
    }
    if (setIfMissing) {
        Object.keys(setIfMissing).forEach((path) => {
            result.push(new SetIfMissingPatch(patch.id, path, setIfMissing[path]));
        });
    }
    if (unset) {
        unset.forEach((path) => {
            result.push(new UnsetPatch(patch.id, path));
        });
    }
    if (diffMatchPatch) {
        Object.keys(diffMatchPatch).forEach((path) => {
            result.push(new DiffMatchPatch(patch.id, path, diffMatchPatch[path]));
        });
    }
    if (inc) {
        Object.keys(inc).forEach((path) => {
            result.push(new IncPatch(patch.id, path, inc[path]));
        });
    }
    if (dec) {
        Object.keys(dec).forEach((path) => {
            result.push(new IncPatch(patch.id, path, -dec[path]));
        });
    }
    if (insert) {
        let location;
        let path;
        const spec = insert;
        if ('before' in spec) {
            location = 'before';
            path = spec.before;
        }
        else if ('after' in spec) {
            location = 'after';
            path = spec.after;
        }
        else if ('replace' in spec) {
            location = 'replace';
            path = spec.replace;
        }
        else {
            throw new Error('Invalid insert patch');
        }
        result.push(new InsertPatch(patch.id, location, path, spec.items));
    }
    return result;
}

/**
 * An immutable probe/writer for plain JS objects that will never mutate
 * the provided _value in place. Each setter returns a new (wrapped) version
 * of the value.
 */
class ImmutableAccessor {
    _value;
    path;
    constructor(value, path) {
        this._value = value;
        this.path = path || [];
    }
    containerType() {
        if (Array.isArray(this._value)) {
            return 'array';
        }
        else if (this._value !== null && typeof this._value === 'object') {
            return 'object';
        }
        return 'primitive';
    }
    // Common reader, supported by all containers
    get() {
        return this._value;
    }
    // Array reader
    length() {
        if (!Array.isArray(this._value)) {
            throw new Error("Won't return length of non-indexable _value");
        }
        return this._value.length;
    }
    getIndex(i) {
        if (!Array.isArray(this._value)) {
            return false;
        }
        if (i >= this.length()) {
            return null;
        }
        return new ImmutableAccessor(this._value[i], this.path.concat(i));
    }
    // Object reader
    hasAttribute(key) {
        return isRecord(this._value) ? this._value.hasOwnProperty(key) : false;
    }
    attributeKeys() {
        return isRecord(this._value) ? Object.keys(this._value) : [];
    }
    getAttribute(key) {
        if (!isRecord(this._value)) {
            throw new Error('getAttribute only applies to plain objects');
        }
        if (!this.hasAttribute(key)) {
            return null;
        }
        return new ImmutableAccessor(this._value[key], this.path.concat(key));
    }
    // Common writer, supported by all containers
    set(value) {
        return value === this._value ? this : new ImmutableAccessor(value, this.path);
    }
    // array writer interface
    setIndex(i, value) {
        if (!Array.isArray(this._value)) {
            throw new Error('setIndex only applies to arrays');
        }
        if (value === this._value[i]) {
            return this;
        }
        const nextValue = this._value.slice();
        nextValue[i] = value;
        return new ImmutableAccessor(nextValue, this.path);
    }
    setIndexAccessor(i, accessor) {
        return this.setIndex(i, accessor.get());
    }
    unsetIndices(indices) {
        if (!Array.isArray(this._value)) {
            throw new Error('unsetIndices only applies to arrays');
        }
        const length = this._value.length;
        const nextValue = [];
        // Copy every _value _not_ in the indices array over to the newValue
        for (let i = 0; i < length; i++) {
            if (indices.indexOf(i) === -1) {
                nextValue.push(this._value[i]);
            }
        }
        return new ImmutableAccessor(nextValue, this.path);
    }
    insertItemsAt(pos, items) {
        if (!Array.isArray(this._value)) {
            throw new Error('insertItemsAt only applies to arrays');
        }
        let nextValue;
        if (this._value.length === 0 && pos === 0) {
            nextValue = items;
        }
        else {
            nextValue = this._value.slice(0, pos).concat(items).concat(this._value.slice(pos));
        }
        return new ImmutableAccessor(nextValue, this.path);
    }
    // Object writer interface
    setAttribute(key, value) {
        if (!isRecord(this._value)) {
            throw new Error('Unable to set attribute of non-object container');
        }
        if (value === this._value[key]) {
            return this;
        }
        const nextValue = Object.assign({}, this._value, { [key]: value });
        return new ImmutableAccessor(nextValue, this.path);
    }
    setAttributeAccessor(key, accessor) {
        return this.setAttribute(key, accessor.get());
    }
    unsetAttribute(key) {
        if (!isRecord(this._value)) {
            throw new Error('Unable to unset attribute of non-object container');
        }
        const nextValue = Object.assign({}, this._value);
        delete nextValue[key];
        return new ImmutableAccessor(nextValue, this.path);
    }
}
function isRecord(value) {
    return value !== null && typeof value === 'object';
}

class Patcher {
    patches;
    constructor(patch) {
        this.patches = parsePatch(patch);
    }
    apply(value) {
        // Apply just makes a root accessor around the provided
        // value, then applies the patches. Due to the use of
        // ImmutableAccessor it is guaranteed to return either the
        // exact same object it was provided (in the case of no changes),
        // or a completely new object. It will never mutate the object in place.
        const accessor = new ImmutableAccessor(value);
        return this.applyViaAccessor(accessor).get();
    }
    // If you want to use your own accessor implementation, you can use this method
    // to invoke the patcher. Since all subsequent accessors for children of this accessor
    // are obtained through the methods in the accessors, you retain full control of the
    // implementation throguhgout the application. Have a look in ImmutableAccessor
    // to see an example of how accessors are implemented.
    applyViaAccessor(accessor) {
        let result = accessor;
        const idAccessor = accessor.getAttribute('_id');
        if (!idAccessor) {
            throw new Error('Cannot apply patch to document with no _id');
        }
        const id = idAccessor.get();
        for (const patch of this.patches) {
            if (patch.id !== id) {
                // Ignore patches that are not targetted at this document
                continue;
            }
            const matcher = Matcher.fromPath(patch.path).setPayload(patch);
            result = process(matcher, result);
        }
        return result;
    }
}
// Recursively (depth first) follows any leads generated by the matcher, expecting
// a patch to be the payload. When matchers report a delivery, the
// apply(targets, accessor) is called on the patch
function process(matcher, accessor) {
    let result = accessor;
    // Every time we execute the matcher a new set of leads is generated. Each lead
    // is a target (being an index, an attribute name or a range) in the form of an
    // Expression instance. For each lead target there is also a matcher. Our job is to obtain
    // accessor(s) for each target (there might be more than one, since the targets may
    // be ranges) and run the provided matcher on those accessors.
    const { leads, delivery } = matcher.match(accessor);
    leads.forEach((lead) => {
        if (lead.target.isIndexReference()) {
            lead.target.toIndicies().forEach((i) => {
                const item = result.getIndex(i);
                if (!item) {
                    throw new Error('Index out of bounds');
                }
                result = result.setIndexAccessor(i, process(lead.matcher, item));
            });
        }
        else if (lead.target.isAttributeReference()) {
            const oldValueAccessor = result.getAttribute(lead.target.name());
            if (!oldValueAccessor) {
                // Don't follow lead, no such attribute
                return;
            }
            const newValueAccessor = process(lead.matcher, oldValueAccessor);
            if (oldValueAccessor !== newValueAccessor) {
                result = result.setAttributeAccessor(lead.target.name(), newValueAccessor);
            }
        }
        else {
            throw new Error(`Unable to handle target ${lead.target.toString()}`);
        }
    });
    // Each time we run the matcher, we might also get a delivery. This means that a
    // term in the jsonpath terminated here and the patch should be applied. The delivery
    // arrives in the form of an array of targets and a payload (which in this application
    // is the patch). Conveniently the patches accept an array of targets and an accessor
    // to do its work, so here we just pass those to the patch and we're done.
    if (delivery && isPatcher(delivery.payload)) {
        const patch = delivery.payload;
        result = patch.apply(delivery.targets, result);
    }
    return result;
}
function isPatcher(payload) {
    return Boolean(payload &&
        typeof payload === 'object' &&
        payload !== null &&
        'apply' in payload &&
        typeof payload.apply === 'function');
}

/**
 * Locally unique id's. We use this to generate transaction ids, and they don't have to be
 * cryptographically unique, as the worst that can happen is that they get rejected because
 * of a collision, and then we should just retry with a new id.
 */
const luid = uuid;

const debug = debugIt('mutator-document');

/**
 * A mutation describing a number of operations on a single document.
 * This should be considered an immutable structure. Mutations are compiled
 * on first application, and any changes in properties will not effectively
 * change its behavior after that.
 *
 * @internal
 */
class Mutation {
    params;
    compiled;
    _appliesToMissingDocument;
    constructor(options) {
        this.params = options;
    }
    get transactionId() {
        return this.params.transactionId;
    }
    get transition() {
        return this.params.transition;
    }
    get identity() {
        return this.params.identity;
    }
    get previousRev() {
        return this.params.previousRev;
    }
    get resultRev() {
        return this.params.resultRev;
    }
    get mutations() {
        return this.params.mutations;
    }
    get timestamp() {
        if (typeof this.params.timestamp === 'string') {
            return new Date(this.params.timestamp);
        }
        return undefined;
    }
    get effects() {
        return this.params.effects;
    }
    assignRandomTransactionId() {
        this.params.transactionId = luid();
        this.params.resultRev = this.params.transactionId;
    }
    appliesToMissingDocument() {
        if (typeof this._appliesToMissingDocument !== 'undefined') {
            return this._appliesToMissingDocument;
        }
        // Only mutations starting with a create operation apply to documents that do not exist ...
        const firstMut = this.mutations[0];
        if (firstMut) {
            this._appliesToMissingDocument = Boolean(firstMut.create || firstMut.createIfNotExists || firstMut.createOrReplace);
        }
        else {
            this._appliesToMissingDocument = true;
        }
        return this._appliesToMissingDocument;
    }
    // Compiles all mutations into a handy function
    compile() {
        const operations = [];
        this.mutations.forEach((mutation) => {
            if (mutation.create) {
                // TODO: Fail entire patch if document did exist
                const create = mutation.create || {};
                operations.push((doc) => {
                    if (doc) {
                        return doc;
                    }
                    return Object.assign(create, {
                        _createdAt: create._createdAt || this.params.timestamp,
                    });
                });
                return;
            }
            if (mutation.createIfNotExists) {
                const createIfNotExists = mutation.createIfNotExists || {};
                operations.push((doc) => doc === null
                    ? Object.assign(createIfNotExists, {
                        _createdAt: createIfNotExists._createdAt || this.params.timestamp,
                    })
                    : doc);
                return;
            }
            if (mutation.createOrReplace) {
                const createOrReplace = mutation.createOrReplace || {};
                operations.push(() => Object.assign(createOrReplace, {
                    _createdAt: createOrReplace._createdAt || this.params.timestamp,
                }));
                return;
            }
            if (mutation.delete) {
                operations.push(() => null);
                return;
            }
            if (mutation.patch) {
                if ('query' in mutation.patch) {
                    // @todo Warn/throw? Investigate if this can ever happen
                    return;
                }
                const patch = new Patcher(mutation.patch);
                operations.push((doc) => patch.apply(doc));
                return;
            }
            throw new Error(`Unsupported mutation ${JSON.stringify(mutation, null, 2)}`);
        });
        // Assign `_updatedAt` to the timestamp of the mutation if set
        if (typeof this.params.timestamp === 'string') {
            operations.push((doc) => {
                return doc ? Object.assign(doc, { _updatedAt: this.params.timestamp }) : null;
            });
        }
        const prevRev = this.previousRev;
        const rev = this.resultRev || this.transactionId;
        this.compiled = (doc) => {
            if (prevRev && doc && prevRev !== doc._rev) {
                throw new Error(`Previous revision for this mutation was ${prevRev}, but the document revision is ${doc._rev}`);
            }
            let result = doc;
            for (const operation of operations) {
                result = operation(result);
            }
            // Should update _rev?
            if (result && rev) {
                // Ensure that result is a unique object, even if the operation was a no-op
                if (result === doc) {
                    result = Object.assign({}, doc);
                }
                result._rev = rev;
            }
            return result;
        };
    }
    apply(document) {
        debug('Applying mutation %O to document %O', this.mutations, document);
        if (!this.compiled) {
            this.compile();
        }
        const result = this.compiled(document);
        debug('  => %O', result);
        return result;
    }
    static applyAll(document, mutations) {
        return mutations.reduce((doc, mutation) => mutation.apply(doc), document);
    }
    // Given a number of yet-to-be-committed mutation objects, collects them into one big mutation
    // any metadata like transactionId is ignored and must be submitted by the client. It is assumed
    // that all mutations are on the same document.
    // TOOO: Optimize mutations, eliminating mutations that overwrite themselves!
    static squash(document, mutations) {
        const squashed = mutations.reduce((result, mutation) => result.concat(...mutation.mutations), []);
        return new Mutation({ mutations: squashed });
    }
}

// TODO: When we have timestamps on mutation notifications, we can reject incoming mutations that are older
/**
 * Models a document as it is changed by our own local patches and remote patches coming in from
 * the server. Consolidates incoming patches with our own submitted patches and maintains two
 * versions of the document. EDGE is the optimistic document that the user sees that will always
 * immediately reflect whatever she is doing to it, and HEAD which is the confirmed version of the
 * document consistent with the mutations we have received from the server. As long as nothing out of
 * the ordinary happens, we can track all changes by hooking into the onMutation callback, but we
 * must also respect onRebase events that fire when we have to backtrack because one of our optimistically
 * applied patches were rejected, or some bastard was able to slip a mutation in between ours own.
 *
 * @internal
 */
class Document {
    /**
     * Incoming patches from the server waiting to be applied to HEAD
     */
    incoming = [];
    /**
     * Patches we know has been subitted to the server, but has not been seen yet in the return channel
     * so we can't be sure about the ordering yet (someone else might have slipped something between them)
     */
    submitted = [];
    /**
     * Pending mutations
     */
    pending = [];
    /**
     * Our model of the document according to the incoming patches from the server
     */
    HEAD;
    /**
     * Our optimistic model of what the document will probably look like as soon as all our patches
     * have been processed. Updated every time we stage a new mutation, but also might revert back
     * to previous states if our mutations fail, or could change if unexpected mutations arrive
     * between our own. The `onRebase` callback will be called when EDGE changes in this manner.
     */
    EDGE;
    /**
     * Called with the EDGE document when that document changes for a reason other than us staging
     * a new patch or receiving a mutation from the server while our EDGE is in sync with HEAD:
     * I.e. when EDGE changes because the order of mutations has changed in relation to our
     * optimistic predictions.
     */
    onRebase;
    /**
     * Called when we receive a patch in the normal order of things, but the mutation is not ours
     */
    onMutation;
    /**
     * Called when consistency state changes with the boolean value of the current consistency state
     */
    onConsistencyChanged;
    /**
     * Called whenever a new incoming mutation comes in. These are always ordered correctly.
     */
    onRemoteMutation;
    /**
     * We are consistent when there are no unresolved mutations of our own, and no un-applicable
     * incoming mutations. When this has been going on for too long, and there has been a while
     * since we staged a new mutation, it is time to reset your state.
     */
    inconsistentAt = null;
    /**
     * The last time we staged a patch of our own. If we have been inconsistent for a while, but it
     * hasn't been long since we staged a new mutation, the reason is probably just because the user
     * is typing or something.
     *
     * Should be used as a guard against resetting state for inconsistency reasons.
     */
    lastStagedAt = null;
    constructor(doc) {
        this.reset(doc);
        this.HEAD = doc;
        this.EDGE = doc;
    }
    // Reset the state of the Document, used to recover from unsavory states by reloading the document
    reset(doc) {
        this.incoming = [];
        this.submitted = [];
        this.pending = [];
        this.inconsistentAt = null;
        this.HEAD = doc;
        this.EDGE = doc;
        this.considerIncoming();
        this.updateConsistencyFlag();
    }
    // Call when a mutation arrives from Sanity
    arrive(mutation) {
        this.incoming.push(mutation);
        this.considerIncoming();
        this.updateConsistencyFlag();
    }
    // Call to signal that we are submitting a mutation. Returns a callback object with a
    // success and failure handler that must be called according to the outcome of our
    // submission.
    stage(mutation, silent) {
        if (!mutation.transactionId) {
            throw new Error('Mutations _must_ have transactionId when submitted');
        }
        this.lastStagedAt = new Date();
        debug('Staging mutation %s (pushed to pending)', mutation.transactionId);
        this.pending.push(mutation);
        this.EDGE = mutation.apply(this.EDGE);
        if (this.onMutation && !silent) {
            this.onMutation({
                mutation,
                document: this.EDGE,
                remote: false,
            });
        }
        const txnId = mutation.transactionId;
        this.updateConsistencyFlag();
        return {
            success: () => {
                this.pendingSuccessfullySubmitted(txnId);
                this.updateConsistencyFlag();
            },
            failure: () => {
                this.pendingFailed(txnId);
                this.updateConsistencyFlag();
            },
        };
    }
    // Call to check if everything is nice and quiet and there are no unresolved mutations.
    // Means this model thinks both HEAD and EDGE is up to date with what the server sees.
    isConsistent() {
        return !this.inconsistentAt;
    }
    // Private
    // Attempts to apply any resolvable incoming patches to HEAD. Will keep patching as long as there
    // are applicable patches to be applied
    considerIncoming() {
        let mustRebase = false;
        let nextMut;
        const rebaseMutations = [];
        // Filter mutations that are older than the document
        if (this.HEAD && this.HEAD._updatedAt) {
            const updatedAt = new Date(this.HEAD._updatedAt);
            if (this.incoming.find((mut) => mut.timestamp && mut.timestamp < updatedAt)) {
                this.incoming = this.incoming.filter((mut) => mut.timestamp && mut.timestamp < updatedAt);
            }
        }
        // Keep applying mutations as long as any apply
        let protect = 0;
        do {
            // Find next mutation that can be applied to HEAD (if any)
            if (this.HEAD) {
                const HEAD = this.HEAD;
                nextMut = HEAD._rev ? this.incoming.find((mut) => mut.previousRev === HEAD._rev) : undefined;
            }
            else {
                // When HEAD is null, that means the document is currently deleted. Only mutations that start with a create
                // operation will be considered.
                nextMut = this.incoming.find((mut) => mut.appliesToMissingDocument());
            }
            if (nextMut) {
                const applied = this.applyIncoming(nextMut);
                mustRebase = mustRebase || applied;
                if (mustRebase) {
                    rebaseMutations.push(nextMut);
                }
                if (protect++ > 10) {
                    throw new Error(`Mutator stuck flushing incoming mutations. Probably stuck here: ${JSON.stringify(nextMut)}`);
                }
            }
        } while (nextMut);
        if (this.incoming.length > 0 && debug.enabled) {
            debug('Unable to apply mutations %s', this.incoming.map((mut) => mut.transactionId).join(', '));
        }
        if (mustRebase) {
            this.rebase(rebaseMutations);
        }
    }
    // check current consistency state, update flag and invoke callback if needed
    updateConsistencyFlag() {
        const wasConsistent = this.isConsistent();
        const isConsistent = this.pending.length === 0 && this.submitted.length === 0 && this.incoming.length === 0;
        // Update the consistency state, taking care not to update the timestamp if we were inconsistent and still are
        if (isConsistent) {
            this.inconsistentAt = null;
        }
        else if (!this.inconsistentAt) {
            this.inconsistentAt = new Date();
        }
        // Handle onConsistencyChanged callback
        if (wasConsistent != isConsistent && this.onConsistencyChanged) {
            if (isConsistent) {
                debug('Buffered document is inconsistent');
            }
            else {
                debug('Buffered document is consistent');
            }
            this.onConsistencyChanged(isConsistent);
        }
    }
    // apply an incoming patch that has been prequalified as the next in line for this document
    applyIncoming(mut) {
        if (!mut) {
            return false;
        }
        if (!mut.transactionId) {
            throw new Error('Received incoming mutation without a transaction ID');
        }
        debug('Applying mutation %s -> %s to rev %s', mut.previousRev, mut.resultRev, this.HEAD && this.HEAD._rev);
        this.HEAD = mut.apply(this.HEAD);
        if (this.onRemoteMutation) {
            this.onRemoteMutation(mut);
        }
        // Eliminate from incoming set
        this.incoming = this.incoming.filter((m) => m.transactionId !== mut.transactionId);
        if (this.hasUnresolvedMutations()) {
            const needRebase = this.consumeUnresolved(mut.transactionId);
            if (debug.enabled) {
                debug(`Incoming mutation ${mut.transactionId} appeared while there were pending or submitted local mutations`);
                debug(`Submitted txnIds: ${this.submitted.map((m) => m.transactionId).join(', ')}`);
                debug(`Pending txnIds: ${this.pending.map((m) => m.transactionId).join(', ')}`);
                debug(`needRebase === %s`, needRebase);
            }
            return needRebase;
        }
        debug(`Remote mutation %s arrived w/o any pending or submitted local mutations`, mut.transactionId);
        this.EDGE = this.HEAD;
        if (this.onMutation) {
            this.onMutation({
                mutation: mut,
                document: this.EDGE,
                remote: true,
            });
        }
        return false;
    }
    /**
     * Returns true if there are unresolved mutations between HEAD and EDGE, meaning we have
     * mutations that are still waiting to be either submitted, or to be confirmed by the server.
     *
     * @returns true if there are unresolved mutations between HEAD and EDGE, false otherwise
     */
    hasUnresolvedMutations() {
        return this.submitted.length > 0 || this.pending.length > 0;
    }
    /**
     * When an incoming mutation is applied to HEAD, this is called to remove the mutation from
     * the unresolved state. If the newly applied patch is the next upcoming unresolved mutation,
     * no rebase is needed, but we might have the wrong idea about the ordering of mutations, so in
     * that case we are given the flag `needRebase` to tell us that this mutation arrived out of
     * order in terms of our optimistic version, so a rebase is needed.
     *
     * @param txnId - Transaction ID of the remote mutation
     * @returns true if rebase is needed, false otherwise
     */
    consumeUnresolved(txnId) {
        // If we have nothing queued up, we are in sync and can apply patch with no
        // rebasing
        if (this.submitted.length === 0 && this.pending.length === 0) {
            return false;
        }
        // If we can consume the directly upcoming mutation, we won't have to rebase
        if (this.submitted.length !== 0) {
            if (this.submitted[0].transactionId === txnId) {
                debug(`Remote mutation %s matches upcoming submitted mutation, consumed from 'submitted' buffer`, txnId);
                this.submitted.shift();
                return false;
            }
        }
        else if (this.pending.length > 0 && this.pending[0].transactionId === txnId) {
            // There are no submitted, but some are pending so let's check the upcoming pending
            debug(`Remote mutation %s matches upcoming pending mutation, consumed from 'pending' buffer`, txnId);
            this.pending.shift();
            return false;
        }
        debug('The mutation was not the upcoming mutation, scrubbing. Pending: %d, Submitted: %d', this.pending.length, this.submitted.length);
        // The mutation was not the upcoming mutation, so we'll have to check everything to
        // see if we have an out of order situation
        this.submitted = this.submitted.filter((mut) => mut.transactionId !== txnId);
        this.pending = this.pending.filter((mut) => mut.transactionId !== txnId);
        debug(`After scrubbing: Pending: %d, Submitted: %d`, this.pending.length, this.submitted.length);
        // Whether we had it or not we have either a reordering, or an unexpected mutation
        // so must rebase
        return true;
    }
    pendingSuccessfullySubmitted(pendingTxnId) {
        if (this.pending.length === 0) {
            // If there are no pending, it has probably arrived allready
            return;
        }
        const first = this.pending[0];
        if (first.transactionId === pendingTxnId) {
            // Nice, the pending transaction arrived in order
            this.pending.shift();
            this.submitted.push(first);
            return;
        }
        // Oh, no. Submitted out of order.
        let justSubmitted;
        const stillPending = [];
        this.pending.forEach((mutation) => {
            if (mutation.transactionId === pendingTxnId) {
                justSubmitted = mutation;
                return;
            }
            stillPending.push(mutation);
        });
        // Not found? Hopefully it has already arrived. Might have been forgotten by now
        if (justSubmitted) {
            this.submitted.push(justSubmitted);
        }
        this.pending = stillPending;
        // Must rebase since mutation order has changed
        this.rebase([]);
    }
    pendingFailed(pendingTxnId) {
        this.pending = this.pending.filter((mutation) => mutation.transactionId !== pendingTxnId);
        // Rebase to revert document to what it looked like before the failed mutation
        this.rebase([]);
    }
    rebase(incomingMutations) {
        const oldEdge = this.EDGE;
        this.EDGE = Mutation.applyAll(this.HEAD, this.submitted.concat(this.pending));
        // Copy over rev, since we don't care if it changed, we only care about the content
        if (oldEdge !== null && this.EDGE !== null) {
            oldEdge._rev = this.EDGE._rev;
        }
        const changed = !isEqual(this.EDGE, oldEdge);
        if (changed && this.onRebase) {
            this.onRebase(this.EDGE, incomingMutations, this.pending);
        }
    }
}

/**
 * Implements a buffer for mutations that incrementally optimises the mutations by
 * eliminating set-operations that overwrite earlier set-operations, and rewrite
 * set-operations that change strings into other strings into diffMatchPatch operations.
 *
 * @internal
 */
class SquashingBuffer {
    /**
     * The document forming the basis of this squash
     */
    BASIS;
    /**
     * The document after the out-Mutation has been applied, but before the staged
     * operations are committed.
     */
    PRESTAGE;
    /**
     * setOperations contain the latest set operation by path. If the set-operations are
     * updating strings to new strings, they are rewritten as diffMatchPatch operations,
     * any new set operations on the same paths overwrites any older set operations.
     * Only set-operations assigning plain values to plain values gets optimized like this.
     */
    setOperations;
    /**
     * `documentPresent` is true whenever we know that the document must be present due
     * to preceeding mutations. `false` implies that it may or may not already exist.
     */
    documentPresent;
    /**
     * The operations in the out-Mutation are not able to be optimized any further
     */
    out = [];
    /**
     * Staged mutation operations
     */
    staged;
    /**
     * Internal reusable diffMatchPatch instance
     * @internal
     */
    dmp; // eslint-disable-line camelcase
    constructor(doc) {
        if (doc) {
            debug('Reset mutation buffer to rev %s', doc._rev);
        }
        else {
            debug('Reset mutation buffer state to document being deleted');
        }
        this.staged = [];
        this.setOperations = {};
        this.documentPresent = false;
        this.BASIS = doc;
        this.PRESTAGE = doc;
        // eslint-disable-next-line new-cap
        this.dmp = new DMP.diff_match_patch();
    }
    add(mut) {
        mut.mutations.forEach((op) => this.addOperation(op));
    }
    hasChanges() {
        return this.out.length > 0 || Object.keys(this.setOperations).length > 0;
    }
    /**
     * Extracts the mutations in this buffer.
     * After this is done, the buffer lifecycle is over and the client should
     * create an new one with the new, updated BASIS.
     *
     * @param txnId - Transaction ID
     * @returns A `Mutation` instance if we had outgoing mutations pending, null otherwise
     */
    purge(txnId) {
        this.stashStagedOperations();
        let result = null;
        if (this.out.length > 0) {
            debug('Purged mutation buffer');
            result = new Mutation({
                mutations: this.out,
                resultRev: txnId,
                transactionId: txnId,
            });
        }
        this.out = [];
        this.documentPresent = false;
        return result;
    }
    addOperation(op) {
        // Is this a set patch, and only a set patch, and does it apply to the document at hand?
        if (op.patch &&
            op.patch.set &&
            'id' in op.patch &&
            op.patch.id === this.PRESTAGE?._id &&
            Object.keys(op.patch).length === 2 // `id` + `set`
        ) {
            const setPatch = op.patch.set;
            const unoptimizable = {};
            // Apply all optimisable keys in the patch
            for (const path of Object.keys(setPatch)) {
                if (setPatch.hasOwnProperty(path)) {
                    if (!this.optimiseSetOperation(path, setPatch[path])) {
                        // If not optimisable, add to unoptimizable set
                        unoptimizable[path] = setPatch[path];
                    }
                }
            }
            // If any weren't optimisable, add them to an unoptimised set-operation, then
            // stash everything.
            if (Object.keys(unoptimizable).length > 0) {
                debug('Unoptimizable set-operation detected, purging optimization buffer');
                this.staged.push({ patch: { id: this.PRESTAGE._id, set: unoptimizable } });
                this.stashStagedOperations();
            }
            return;
        }
        // Is this a createIfNotExists for our document?
        if (op.createIfNotExists && this.PRESTAGE && op.createIfNotExists._id === this.PRESTAGE._id) {
            if (!this.documentPresent) {
                // If we don't know that it's present we'll have to stage and stash.
                this.staged.push(op);
                this.documentPresent = true;
                this.stashStagedOperations();
            }
            // Otherwise we can fully ignore it.
            return;
        }
        debug('Unoptimizable mutation detected, purging optimization buffer');
        // console.log("Unoptimizable operation, stashing", JSON.stringify(op))
        // Un-optimisable operations causes everything to be stashed
        this.staged.push(op);
        this.stashStagedOperations();
    }
    /**
     * Attempt to perform one single set operation in an optimised manner, return value
     * reflects whether or not the operation could be performed.
  
     * @param path - The JSONPath to the set operation in question
     * @param nextValue - The value to be set
     * @returns True of optimized, false otherwise
     */
    optimiseSetOperation(path, nextValue) {
        // console.log('optimiseSetOperation', path, nextValue)
        // If target value is not a plain value, unable to optimise
        if (typeof nextValue === 'object') {
            // console.log("Not optimisable because next value is object")
            return false;
        }
        // Check the source values, if there is more than one value being assigned,
        // we won't optimise
        const matches = extractWithPath(path, this.PRESTAGE);
        // If we are not overwriting exactly one key, this cannot be optimised, so we bail
        if (matches.length !== 1) {
            // console.log('Not optimisable because match count is != 1', JSON.stringify(matches))
            return false;
        }
        // Okay, we are assigning exactly one value to exactly one existing slot, so we might optimise
        const match = matches[0];
        // If the value of the match is an array or object, we cannot safely optimise this since the meaning
        // of pre-existing operations might change (in theory, at least), so we bail
        if (typeof match.value === 'object') {
            // console.log("Not optimisable because old value is object")
            return false;
        }
        if (!this.PRESTAGE) {
            // Shouldn't happen, but makes typescript happy
            return false;
        }
        // If the new and old value are the equal, we optimise this operation by discarding it
        // Now, let's build the operation
        let op = null;
        if (match.value === nextValue) {
            // If new and old values are equal, we optimise this by deleting the operation
            // console.log("Omitting operation")
            op = null;
        }
        else if (typeof match.value === 'string' && typeof nextValue === 'string') {
            // console.log("Rewriting to dmp")
            // We are updating a string to another string, so we are making a diffMatchPatch
            try {
                const patch = this.dmp
                    .patch_make(match.value, nextValue)
                    .map((dmpPatch) => dmpPatch.toString())
                    .join('');
                op = { patch: { id: this.PRESTAGE._id, diffMatchPatch: { [path]: patch } } };
            }
            catch {
                // patch_make failed due to unicode issue https://github.com/google/diff-match-patch/issues/59
                return false;
            }
        }
        else {
            // console.log("Not able to rewrite to dmp, making normal set")
            // We are changing the type of the value, so must make a normal set-operation
            op = { patch: { id: this.PRESTAGE._id, set: { [path]: nextValue } } };
        }
        // Let's make a plain, concrete path from the array-path. We use this to keep only the latest set
        // operation touching this path in the buffer.
        const canonicalPath = arrayToJSONMatchPath(match.path);
        // Store this operation, overwriting any previous operations touching this same path
        if (op) {
            this.setOperations[canonicalPath] = op;
        }
        else {
            delete this.setOperations[canonicalPath];
        }
        // Signal that we succeeded in optimizing this patch
        return true;
    }
    stashStagedOperations() {
        // Short circuit if there are no staged operations
        const nextOps = [];
        // Extract the existing outgoing operations if any
        Object.keys(this.setOperations).forEach((key) => {
            const op = this.setOperations[key];
            if (op) {
                nextOps.push(op);
            }
        });
        nextOps.push(...this.staged);
        if (nextOps.length > 0) {
            this.PRESTAGE = new Mutation({ mutations: nextOps }).apply(this.PRESTAGE);
            this.staged = [];
            this.setOperations = {};
        }
        this.out.push(...nextOps);
    }
    /**
     * Rebases given the new base-document
     *
     * @param newBasis - New base document to rebase on
     * @returns New "edge" document with buffered changes integrated
     */
    rebase(newBasis) {
        this.stashStagedOperations();
        if (newBasis === null) {
            // If document was just deleted, we must throw out local changes
            this.out = [];
            this.BASIS = newBasis;
            this.PRESTAGE = newBasis;
            this.documentPresent = false;
        }
        else {
            this.BASIS = newBasis;
            // @todo was this supposed to be `this.out.length > 0`?
            // surely this is always `true`?
            if (this.out) {
                this.PRESTAGE = new Mutation({ mutations: this.out }).apply(this.BASIS);
            }
            else {
                this.PRESTAGE = this.BASIS;
            }
        }
        return this.PRESTAGE;
    }
}

const ONE_MINUTE = 1000 * 60;
/**
 * A wrapper for Document that allows the client to gather mutations on the
 * client side and commit them when it wants to.
 */
class Commit {
    mutations;
    tries;
    resolve;
    reject;
    constructor(mutations, { resolve, reject }) {
        this.mutations = mutations;
        this.tries = 0;
        this.resolve = resolve;
        this.reject = reject;
    }
    apply(doc) {
        return Mutation.applyAll(doc, this.mutations);
    }
    squash(doc) {
        const result = Mutation.squash(doc, this.mutations);
        result.assignRandomTransactionId();
        return result;
    }
}
const mutReducerFn = (acc, mut) => acc.concat(mut.mutations);
/**
 * @internal
 */
class BufferedDocument {
    mutations;
    /**
     * The Document we are wrapping
     */
    document;
    /**
     * The Document with local changes applied
     */
    LOCAL;
    /**
     * Commits that are waiting to be delivered to the server
     */
    commits;
    /**
     * Local mutations that are not scheduled to be committed yet
     */
    buffer;
    /**
     * Assignable event handler for when the buffered document applies a mutation
     */
    onMutation;
    /**
     * Assignable event handler for when a remote mutation happened
     */
    onRemoteMutation;
    /**
     * Assignable event handler for when the buffered document rebased
     */
    onRebase;
    /**
     * Assignable event handler for when the document is deleted
     */
    onDelete;
    /**
     * Assignable event handler for when the state of consistency changed
     */
    onConsistencyChanged;
    /**
     * Assignable event handler for when the buffered document should commit changes
     */
    commitHandler;
    /**
     * Whether or not we are currently commiting
     */
    committerRunning = false;
    constructor(doc) {
        this.buffer = new SquashingBuffer(doc);
        this.document = new Document(doc);
        this.document.onMutation = (msg) => this.handleDocMutation(msg);
        this.document.onRemoteMutation = (mut) => this.onRemoteMutation && this.onRemoteMutation(mut);
        this.document.onRebase = (edge, remoteMutations, localMutations) => this.handleDocRebase(edge, remoteMutations, localMutations);
        this.document.onConsistencyChanged = (msg) => this.handleDocConsistencyChanged(msg);
        this.LOCAL = doc;
        this.mutations = [];
        this.commits = [];
    }
    // Used to reset the state of the local document model. If the model has been inconsistent
    // for too long, it has probably missed a notification, and should reload the document from the server
    reset(doc) {
        if (doc) {
            debug('Document state reset to revision %s', doc._rev);
        }
        else {
            debug('Document state reset to being deleted');
        }
        this.document.reset(doc);
        this.rebase([], []);
        this.handleDocConsistencyChanged(this.document.isConsistent());
    }
    // Add a change to the buffer
    add(mutation) {
        if (this.onConsistencyChanged) {
            this.onConsistencyChanged(false);
        }
        debug('Staged local mutation');
        this.buffer.add(mutation);
        const oldLocal = this.LOCAL;
        this.LOCAL = mutation.apply(this.LOCAL);
        if (this.onMutation && oldLocal !== this.LOCAL) {
            debug('onMutation fired');
            this.onMutation({
                mutation,
                document: this.LOCAL,
                remote: false,
            });
            if (this.LOCAL === null && this.onDelete) {
                this.onDelete(this.LOCAL);
            }
        }
    }
    // Call when a mutation arrives from Sanity
    arrive(mutation) {
        debug('Remote mutation arrived %s -> %s', mutation.previousRev, mutation.resultRev);
        if (mutation.previousRev === mutation.resultRev) {
            throw new Error(`Mutation ${mutation.transactionId} has previousRev === resultRev (${mutation.previousRev})`);
        }
        return this.document.arrive(mutation);
    }
    // Submit all mutations in the buffer to be committed
    commit() {
        return new Promise((resolve, reject) => {
            // Anything to commit?
            if (!this.buffer.hasChanges()) {
                resolve();
                return;
            }
            debug('Committing local changes');
            // Collect current staged mutations into a commit and ...
            const pendingMutations = this.buffer.purge();
            this.commits.push(new Commit(pendingMutations ? [pendingMutations] : [], { resolve, reject }));
            // ... clear the table for the next commit.
            this.buffer = new SquashingBuffer(this.LOCAL);
            this.performCommits();
        });
    }
    // Starts the committer that will try to committ all staged commits to the database
    // by calling the commitHandler. Will keep running until all commits are successfully
    // committed.
    performCommits() {
        if (!this.commitHandler) {
            throw new Error('No commitHandler configured for this BufferedDocument');
        }
        if (this.committerRunning) {
            // We can have only one committer at any given time
            return;
        }
        this._cycleCommitter();
    }
    // TODO: Error handling, right now retries after every error
    _cycleCommitter() {
        const commit = this.commits.shift();
        if (!commit) {
            this.committerRunning = false;
            return;
        }
        this.committerRunning = true;
        const squashed = commit.squash(this.LOCAL);
        const docResponder = this.document.stage(squashed, true);
        const responder = {
            success: () => {
                debug('Commit succeeded');
                docResponder.success();
                commit.resolve();
                // Keep running the committer until no more commits
                this._cycleCommitter();
            },
            failure: () => {
                debug('Commit failed');
                // Re stage commit
                commit.tries += 1;
                if (this.LOCAL !== null) {
                    // Only schedule this commit for a retry of the document still exist to avoid looping
                    // indefinitely when the document was deleted from under our noses
                    this.commits.unshift(commit);
                }
                docResponder.failure();
                // Todo: Need better error handling (i.e. propagate to user and provide means of retrying)
                if (commit.tries < 200) {
                    setTimeout(() => this._cycleCommitter(), Math.min(commit.tries * 1000, ONE_MINUTE));
                }
            },
            cancel: (error) => {
                this.commits.forEach((comm) => comm.reject(error));
                // Throw away waiting commits
                this.commits = [];
                // Reset back to last known state from content lake and cause a rebase that will
                // reset the view in the form
                this.reset(this.document.HEAD);
                // Clear the buffer of recent mutations
                this.buffer = new SquashingBuffer(this.LOCAL);
                // Stop the committer loop
                this.committerRunning = false;
            },
        };
        debug('Posting commit');
        if (this.commitHandler) {
            this.commitHandler({
                mutation: squashed,
                success: responder.success,
                failure: responder.failure,
                cancel: responder.cancel,
            });
        }
    }
    handleDocRebase(edge, remoteMutations, localMutations) {
        this.rebase(remoteMutations, localMutations);
    }
    handleDocumentDeleted() {
        debug('Document deleted');
        // If the document was just deleted, fire the onDelete event with the absolutely latest
        // version of the document before someone deleted it so that the client may revive the
        // document in the last state the user saw it, should they so desire.
        if (this.LOCAL !== null && this.onDelete) {
            this.onDelete(this.LOCAL);
        }
        this.commits = [];
        this.mutations = [];
    }
    handleDocMutation(msg) {
        // If we have no local changes, we can just pass this on to the client
        if (this.commits.length === 0 && !this.buffer.hasChanges()) {
            debug('Document mutated from remote with no local changes');
            this.LOCAL = this.document.EDGE;
            this.buffer = new SquashingBuffer(this.LOCAL);
            if (this.onMutation) {
                this.onMutation(msg);
            }
            return;
        }
        debug('Document mutated from remote with local changes');
        // If there are local edits, and the document was deleted, we need to purge those local edits now
        if (this.document.EDGE === null) {
            this.handleDocumentDeleted();
        }
        // We had local changes, so need to signal rebase
        this.rebase([msg.mutation], []);
    }
    rebase(remoteMutations, localMutations) {
        debug('Rebasing document');
        if (this.document.EDGE === null) {
            this.handleDocumentDeleted();
        }
        const oldLocal = this.LOCAL;
        this.LOCAL = this.commits.reduce((doc, commit) => commit.apply(doc), this.document.EDGE);
        this.LOCAL = this.buffer.rebase(this.LOCAL);
        // Copy over rev, since we don't care if it changed, we only care about the content
        if (oldLocal !== null && this.LOCAL !== null) {
            oldLocal._rev = this.LOCAL._rev;
        }
        const changed = !isEqual(this.LOCAL, oldLocal);
        if (changed && this.onRebase) {
            this.onRebase(this.LOCAL, remoteMutations.reduce(mutReducerFn, []), localMutations.reduce(mutReducerFn, []));
        }
    }
    handleDocConsistencyChanged(isConsistent) {
        if (!this.onConsistencyChanged) {
            return;
        }
        const hasLocalChanges = this.commits.length > 0 || this.buffer.hasChanges();
        if (isConsistent && !hasLocalChanges) {
            this.onConsistencyChanged(true);
        }
        if (!isConsistent) {
            this.onConsistencyChanged(false);
        }
    }
}

export { BufferedDocument, Mutation, arrayToJSONMatchPath, extractWithPath };
//# sourceMappingURL=index.js.map
